{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-09-25 11:19:05 WARNING  From /home/arbiter/.pyenv/versions/3.7.3/envs/ap-submission/lib/python3.7/site-packages/cleverhans/utils_tf.py:341: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import logging\n",
    "from functools import reduce, partial\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Union, Callable\n",
    "import pprint\n",
    "from mkdir_p import mkdir_p\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from flatten_dict import flatten\n",
    "\n",
    "from nnattack.variables import auto_var\n",
    "from params import (\n",
    "    compare_attacks,\n",
    "    compare_defense,\n",
    "    parametric_defense,\n",
    "    \n",
    "    #compare_nns,\n",
    "    \n",
    "    nn_k1_robustness,\n",
    "    nn_k3_robustness,\n",
    "    rf_robustness,\n",
    "    dt_robustness,\n",
    "    lr_ap_robustness,\n",
    "    lr_at_robustness,\n",
    "    mlp_ap_robustness,\n",
    "    mlp_at_robustness,\n",
    "    \n",
    "    tst_scores,\n",
    "    \n",
    "    dt_robustness_figs,\n",
    "    nn_k1_robustness_figs,\n",
    "    nn_k3_robustness_figs,\n",
    "    rf_robustness_figs,\n",
    "    \n",
    "    nn1_def,\n",
    "    nn3_def,\n",
    "    dt_def,\n",
    "    rf_def,\n",
    "    lr_def,\n",
    "    mlp_def,\n",
    ")\n",
    "import params\n",
    "import params_l2\n",
    "from utils import set_plot, get_result, write_to_tex, union_param_key, params_to_dataframe, table_wrapper\n",
    "\n",
    "auto_var.set_variable_value('random_seed', 0)\n",
    "auto_var.set_variable_value('ord', 'inf')\n",
    "auto_var.set_logging_level(0)\n",
    "\n",
    "compare_attacks = compare_attacks()\n",
    "compare_defense = compare_defense()\n",
    "parametric_defense = parametric_defense()\n",
    "tst_scores = tst_scores()\n",
    "\n",
    "#compare_nns = compare_nns()\n",
    "mlp_ap_robustness = mlp_ap_robustness()\n",
    "mlp_at_robustness = mlp_at_robustness()\n",
    "lr_ap_robustness = lr_ap_robustness()\n",
    "lr_at_robustness = lr_at_robustness()\n",
    "nn_k1_robustness = nn_k1_robustness()\n",
    "nn_k3_robustness = nn_k3_robustness()\n",
    "rf_robustness = rf_robustness()\n",
    "dt_robustness = dt_robustness()\n",
    "dt_robustness_figs = dt_robustness_figs()\n",
    "nn_k1_robustness_figs = nn_k1_robustness_figs()\n",
    "nn_k3_robustness_figs = nn_k3_robustness_figs()\n",
    "rf_robustness_figs = rf_robustness_figs()\n",
    "\n",
    "nn1_def = nn1_def()\n",
    "nn3_def = nn3_def()\n",
    "dt_def = dt_def()\n",
    "rf_def = rf_def()\n",
    "lr_def = lr_def()\n",
    "mlp_def = mlp_def()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_latex_figs(exp_name, control_var, caption):\n",
    "    control = ParameterGrid(control_var)\n",
    "    ret = \"\"\"\n",
    "\\\\begin{figure}[ht!]\n",
    "\\\\centering\"\"\"\n",
    "    img_paths = []\n",
    "    for i, g in enumerate(control):\n",
    "        dataset, ord = g['dataset'], g['ord']\n",
    "        img_path = f'./figs/{exp_name}_{dataset}_{ord}.eps'\n",
    "        dataset = dataset.replace(\"_\", \" \")\n",
    "        ret += \"\"\"\n",
    "\\\\subfloat[%s]{\n",
    "    \\\\includegraphics[width=.45\\\\textwidth]{%s}}\"\"\" % (dataset, img_path)\n",
    "        if i % 2 == 1:\n",
    "            ret += \"\\n\"\n",
    "    ret += \"\"\"\n",
    "\\\\caption{%s}\n",
    "\\\\label{fig:%s}\n",
    "\\\\end{figure} \n",
    "\"\"\" % (caption, exp_name)\n",
    "    return ret\n",
    "                      \n",
    "def plot_result(df, exp_name, control_var, variables,\n",
    "                get_title_fn: Union[Callable[[Dict], str], None]=None,\n",
    "                get_label_name_fn: Union[Callable[[Dict], str], None]=None,\n",
    "                get_label_color_fn: Union[Callable[[Dict], str], None]=None, show_plot=True):\n",
    "    ret = []\n",
    "    for g in ParameterGrid(control_var):\n",
    "        temp_df = df\n",
    "                      \n",
    "        if get_title_fn is None:\n",
    "            title = exp_name\n",
    "            for k, v in g.items():\n",
    "                title = title + f\"_{get_var_name(k, v)}\"\n",
    "        else:\n",
    "            title = get_title_fn(g)\n",
    "            \n",
    "        for k, v in g.items():\n",
    "            temp_df = temp_df.loc[df[k] == v]\n",
    "                      \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        for name, group in temp_df.groupby(variables):\n",
    "            #print(name, len(group))\n",
    "            eps_list = [re.findall(r'[-+]?\\d*\\.\\d+|\\d+', t)[0] for t in group.mean().index.tolist()[:-1]]\n",
    "            s = [r for r in group.mean().tolist()[:-1] if not np.isnan(r)]\n",
    "            x = [float(eps_list[i]) for i, r in enumerate(group.mean().tolist()[:-1]) if not np.isnan(r)]\n",
    "                      \n",
    "            if get_label_name_fn is not None:\n",
    "                label = get_label_name(name)\n",
    "            elif isinstance(name, str):\n",
    "                label = get_var_name(variables[0], name)\n",
    "            else:\n",
    "                mod_names = []\n",
    "                for i, n in enumerate(name):\n",
    "                    mod_names.append(get_var_name(variables[i], n))\n",
    "                label = mod_name.join(\"_\")\n",
    "\n",
    "            if get_label_color_fn is not None:\n",
    "                ax.plot(x, s, label=label, linewidth=3.5, color=get_label_color_fn(name))\n",
    "            else:\n",
    "                ax.plot(x, s, label=label, linewidth=3.5)\n",
    "\n",
    "        dataset = g['dataset']\n",
    "        ord = g['ord']\n",
    "        set_plot(fig, ax)\n",
    "        plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "        plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "        ret.append((g, f'./figs/{exp_name}_{dataset}_{ord}.eps'))\n",
    "        if show_plot:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parbox(width, content):\n",
    "    return \"\\\\parbox{%dmm}{\\\\centering %s}\" % (width, content)\n",
    "\n",
    "def knn_attack_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param[0]['ord'],\n",
    "    }\n",
    "    variables = ['attack']\n",
    "    plot_result(df, exp_name, control, variables, show_plot)\n",
    "    return result_latex_figs(exp_name, control, caption)\n",
    "\n",
    "def get_var_name(var, arg):\n",
    "    if var == 'dataset':\n",
    "        return auto_var.get_var_shown_name(var, arg)\n",
    "    return arg.replace('_', '-')\n",
    "\n",
    "def avg_pert_table(exp_name, grid_param, columns, rows, objs:list=None, obj_formats:list=None):\n",
    "    if objs is None:\n",
    "        objs = ['avg_pert']\n",
    "    columns = list(filter(lambda a: a not in ['n_features', 'n_samples', 'n_classes'], columns))\n",
    "    if len(columns) == 0 or len(rows) == 0:\n",
    "        return pd.DataFrame({})\n",
    "    df = params_to_dataframe(grid_param, objs)\n",
    "    \n",
    "    d = OrderedDict()\n",
    "    col_grid = OrderedDict([(c, union_param_key(grid_param, c)) for c in columns])\n",
    "    row_grid = OrderedDict([(r, union_param_key(grid_param, r)) for r in rows])\n",
    "    for i, obj in enumerate(objs):\n",
    "        temp_df = df.groupby(columns + rows)[obj].mean()\n",
    "        temp_df_sem = df.groupby(columns + rows)[obj].sem()\n",
    "        \n",
    "        if obj == 'tst_score':\n",
    "            assert columns[0] == 'model'\n",
    "        for col in ParameterGrid(col_grid):\n",
    "            col_k = tuple(col[c] for c in columns)\n",
    "            col_name = tuple([get_var_name(c, col[c]) for c in columns[:-1]] \\\n",
    "                             + [\"%s-%s\" % (get_var_name(columns[-1], col[columns[-1]]), obj.replace(\"_\", \"-\"))])\n",
    "            d[col_name] = {}\n",
    "            for row in ParameterGrid(row_grid):\n",
    "                row_k = tuple(row[r] for r in rows)\n",
    "                row_name = tuple(get_var_name(r, row[r]) for r in rows)\n",
    "                if (col_k + row_k) in temp_df:\n",
    "                    #d[col_name][row_name] = \"$%.3f \\pm %.3f$\" % (temp_df[col_k + row_k], temp_df_sem[col_k + row_k])\n",
    "                    if obj_formats is None:\n",
    "                        str_format = \"$%.3f$\"\n",
    "                    else:\n",
    "                        str_format = obj_formats[i]\n",
    "                    d[col_name][row_name] = str_format % (temp_df[col_k + row_k])\n",
    "                    if temp_df[col_k + row_k] < 1:\n",
    "                        d[col_name][row_name] = d[col_name][row_name].replace(\"0.\", \".\")\n",
    "                else:\n",
    "                    d[col_name][row_name] = -1\n",
    "\n",
    "    #d = OrderedDict([(k, d[k]) for k in d.keys()])\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "def dataset_stat_column(df, grid_param, columns, rows):\n",
    "    if (\"n_features\" not in columns) and (\"n_samples\" not in columns) and (\"n_classes\" not in columns) \\\n",
    "        and (\"n_train\" not in columns) and (\"n_test\" not in columns):\n",
    "        return df\n",
    "    \n",
    "    column_names = {\n",
    "        'n_train': '\\# training',\n",
    "        'n_test': '\\# testing',\n",
    "        'n_features': '\\# features',\n",
    "        'n_samples': '\\# examples',\n",
    "        'n_classes': '\\# classes',\n",
    "    }\n",
    "    \n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    datasets = union_param_key(grid_param, \"dataset\")\n",
    "    if len(d.keys()) > 0:\n",
    "        first_key = list(d.keys())[0]\n",
    "        row_len = 1 if isinstance(d[first_key], str) else len(first_key)\n",
    "        col_len = 1 if isinstance(first_key, str) else len(first_key)\n",
    "        ori_cols = list(d.keys())\n",
    "    else:\n",
    "        row_len = 1\n",
    "        col_len = 1\n",
    "        ori_cols = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        X, y, _ = auto_var.get_var_with_argument(\"dataset\", dataset)\n",
    "        row_name = (get_var_name(\"dataset\", dataset), )\n",
    "        for col in columns:\n",
    "            if col not in column_names:\n",
    "                continue\n",
    "            column_name = tuple(['-' for _ in range(col_len-1)] + [column_names[col]])\n",
    "            if col == \"n_features\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[1]\n",
    "            elif col == \"n_samples\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[0]\n",
    "            elif col == \"n_train\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[0] - 200\n",
    "            elif col == \"n_test\":\n",
    "                d.setdefault(column_name, {})[row_name] = 100\n",
    "            elif col == \"n_classes\":\n",
    "                d.setdefault(column_name, {})[row_name] = len(np.unique(y))\n",
    "                \n",
    "    for col in ori_cols:\n",
    "        d.move_to_end(col)\n",
    "        \n",
    "    return pd.DataFrame(d)\n",
    "    \n",
    "def cmp_ratio(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    cmp_base = []\n",
    "    \n",
    "    i = 0\n",
    "    for col, col_dict in d.items():\n",
    "        ret[col] = col_dict\n",
    "        if 'avg-pert' not in col[1]:\n",
    "            continue\n",
    "        if i == 0 or i == 1:\n",
    "            cmp_base.append(col_dict)\n",
    "            i += 1\n",
    "            continue\n",
    "        temp = {}\n",
    "        for k, v in col_dict.items():\n",
    "            if v == -1 or cmp_base[i % 2][k] == -1:\n",
    "                temp[k] = int(-1)\n",
    "            else:\n",
    "                v = v.replace(\"$\", \"\")\n",
    "                t = cmp_base[i % 2][k].replace(\"$\", \"\")\n",
    "                temp[k] = \"$%.2f$\" % (float(v) / float(t))\n",
    "        \n",
    "        ret[tuple([c for c in col[:-1]] + [\"%s imp.\" % col[-1]])] = temp\n",
    "        i += 1\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def max_imp(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    def add_new_col(col_list, ret):\n",
    "        new_col = {}\n",
    "        \n",
    "        for attack_name in [col_list[0][0][1], col_list[1][0][1]]:\n",
    "            temp = list(filter(lambda t: t[0][1] == attack_name, col_list))\n",
    "            imps = []\n",
    "            for c in temp:\n",
    "                imps.append([float(v.replace(\"$\", \"\")) if v != -1 else -1 for _, v in c[1].items()])\n",
    "            imps = (np.array(imps).T).argmax(axis=1)\n",
    "\n",
    "            new_col = {}\n",
    "            new_col_imp = {}\n",
    "            new_col_eps = {}\n",
    "            pcol = temp[0][0]\n",
    "            \n",
    "            if 'd' in pcol[0].split(\"-\")[-1]:\n",
    "                tt = pcol[0].split(\"-\")\n",
    "                tt.pop(-2)\n",
    "            else:\n",
    "                tt = pcol[0].split(\"-\")[:-1]\n",
    "            new_col_name = (\"-\".join(tt), pcol[1])\n",
    "            new_col_imp_name = (\"-\".join(tt), (\"%s imp.\" % pcol[1]))\n",
    "            new_col_eps_name = (\"-\".join(tt), (\"%s $\\\\epsilon$\" % pcol[1]))\n",
    "            for i, idx in enumerate(imps):\n",
    "                k, v = list(temp[idx][1].items())[i]\n",
    "                new_col[k] = v\n",
    "                k, v = list(temp[idx][2].items())[i]\n",
    "                new_col_imp[k] = v \n",
    "\n",
    "                if 'd' in temp[idx][0][0].split(\"-\")[-1]:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-2]) * 0.01))[1:]\n",
    "                else:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-1]) * 0.01))[1:]\n",
    "\n",
    "            ret[new_col_eps_name] = new_col_eps\n",
    "            ret[new_col_name] = new_col\n",
    "            ret[new_col_imp_name] = new_col_imp\n",
    "    \n",
    "    prev_col = None\n",
    "    temp = []\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        if 'd' in col[0].split(\"-\")[-1]:\n",
    "            check_idx = -2\n",
    "        else:\n",
    "            check_idx = -1\n",
    "            \n",
    "        if i == 0 or i == 1:\n",
    "            ret[col] = col_dict\n",
    "            continue\n",
    "            \n",
    "        if len(temp) == 0:\n",
    "            temp.append(col_dict)\n",
    "        elif i % 2 == 1:\n",
    "            temp[-1] = (prev_col, temp[-1], col_dict)\n",
    "            if i == (len(d.items())-1):\n",
    "                add_new_col(temp, ret)\n",
    "        else:\n",
    "            if col[0].split(\"-\")[:check_idx] != prev_col[0].split(\"-\")[:check_idx]:\n",
    "                add_new_col(temp, ret)\n",
    "                temp = [col_dict]\n",
    "            else:\n",
    "                temp.append(col_dict)\n",
    "                \n",
    "        prev_col = col\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def bold_best(df, reverse=False):\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    temp = []\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        temp.append([])\n",
    "        for row, row_value in col_dict.items():\n",
    "            if isinstance(row_value, str):\n",
    "                temp[-1].append(float(row_value.replace(\"$\", '')))\n",
    "            else:\n",
    "                temp[-1].append(np.inf if reverse else -np.inf)\n",
    "            \n",
    "    temp = np.array(temp).T\n",
    "    if reverse:\n",
    "        best_idx = temp.argmin(axis=1)\n",
    "    else:\n",
    "        best_idx = temp.argmax(axis=1)\n",
    "        \n",
    "    ret = OrderedDict()\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        ret[col] = {}\n",
    "        for j, (row, row_value) in enumerate(col_dict.items()):\n",
    "            if not isinstance(row_value, str):\n",
    "                ret[col][row] = row_value\n",
    "            else:\n",
    "                if float(row_value[1:-1]) == temp[j][best_idx[j]]:\n",
    "                    ret[col][row] = \"$\\\\mathbf{\" + row_value[1:-1] + \"}$\"\n",
    "                else:\n",
    "                    ret[col][row] = row_value\n",
    "\n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def gen_table(exp_name, grid_params, columns, rows, objs=None,\n",
    "              combine_method=None, additionals=None, obj_formats=None):\n",
    "    if objs is None:\n",
    "        objs = ['avg_pert']\n",
    "    df = pd.DataFrame({})\n",
    "    if combine_method is None:\n",
    "        df = avg_pert_table(exp_name, grid_params, columns, rows, objs, obj_formats)\n",
    "        if additionals:\n",
    "            for fn in additionals:\n",
    "                df = fn(df)\n",
    "    else:\n",
    "        dfs = []\n",
    "        for g in grid_params:\n",
    "            df = avg_pert_table(exp_name, g, columns, rows, objs, obj_formats)\n",
    "            if additionals:\n",
    "                for fn in additionals:\n",
    "                    df = fn(df)\n",
    "            dfs.append(df)\n",
    "        df = pd.concat(dfs, axis=combine_method)\n",
    "    \n",
    "    if 'dataset' in rows:\n",
    "        df = dataset_stat_column(df, grid_param, columns, rows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc(df, grid_param):\n",
    "    # col = ['model', 'attack']\n",
    "    ret = OrderedDict()\n",
    "    tst_df = params_to_dataframe(grid_param, ['tst_score'])\n",
    "\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    models = set([c[0] for c, _ in d.items()])\n",
    "    \n",
    "    prev_col =None\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        new_col_dict = OrderedDict({})\n",
    "        if i == 0:\n",
    "            for row, _ in col_dict.items():\n",
    "                temp_df = tst_df[(tst_df['model'] == col[0].replace(\"-\", \"_\"))\n",
    "                                 & (tst_df['attack'] == 'blackbox') \n",
    "                                 & (tst_df['dataset'] == row[0].replace(\"-\", \"_\"))]\n",
    "                new_col_dict[row] = \"$%.2f$\" % temp_df['tst_score'].mean()\n",
    "            ret[(col[0], col[1].replace('-avg-pert', ' tst acc.'))] = new_col_dict\n",
    "            \n",
    "        elif '\\\\epsilon' in col[1]:\n",
    "            m = re.match(r\"(?P<attack>[a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", col[1])\n",
    "            attack_name = m.group(\"attack\")[:-9].replace(\"-\", \"_\") # remove '$epsilon$'\n",
    "            for row, row_val in col_dict.items():\n",
    "                if 'd' in col[0].split('-')[-1]:\n",
    "                    model_name = '%s-%d-%s' % ('-'.join(col[0].split('-')[:-1]),\n",
    "                                               int(float(row_val.replace(\"$\", \"\"))*100),\n",
    "                                               col[0].split('-')[-1],)\n",
    "                else:\n",
    "                    model_name = \"%s-%d\" % (col[0], int(float(row_val.replace(\"$\", \"\"))*100))\n",
    "                model_name = model_name.replace(\"-\", \"_\")\n",
    "                temp_df = tst_df[(tst_df['model'] == model_name)\n",
    "                                 & (tst_df['attack'] == attack_name) \n",
    "                                 & (tst_df['dataset'] == row[0].replace(\"-\", \"_\"))]\n",
    "                new_col_dict[row] = \"$%.2f$\" % temp_df['tst_score'].mean()\n",
    "            ret[(col[0], col[1].replace('-avg-pert $\\\\epsilon$', ' tst acc.'))] = new_col_dict\n",
    "            \n",
    "        prev_col = col\n",
    "        ret[col] = col_dict\n",
    "    return pd.DataFrame(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvement(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        if i != 0:\n",
    "            ret[col] = {}\n",
    "        for row, row_value in col_dict.items():\n",
    "            if i == 0:\n",
    "                ref = col_dict\n",
    "                value = 1.0\n",
    "            elif ref[row] == -1 or row_value == -1:\n",
    "                value = -1.\n",
    "            else:\n",
    "                value = (float(row_value.replace(\"$\", '')) / float(ref[row].replace(\"$\", '')))\n",
    "                \n",
    "            if i != 0:\n",
    "                ret[col][row] = \"$%.2f$\" % value\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "_, exp_name, grid_param, _ = compare_defense()\n",
    "avg_caption = \"\"\"\n",
    "The \\defenderscore across four nonparametric classifiers and corresponding competitors.\n",
    "A number greater than one indicates that the defense yields a more robust model, \n",
    "while less than one indicates less robustness (higher is better; best is in bold).\n",
    "The \\defenderscore for undefended classifiers are always one.\n",
    "\"\"\"\n",
    "\n",
    "table_str = gen_table(\n",
    "                exp_name, grid_param, ['model', 'attack'], ['dataset'], combine_method=1,\n",
    "                objs=['avg_pert'], additionals=[improvement, bold_best]\n",
    "            ).to_latex(escape=False)\n",
    "table_str = re.sub(r\"[\\s]*adv-nn-k1-30 & [\\s]*robustv2-nn-k1-30 & [\\s]*advPruning-nn-k1-30\",\n",
    "                   r\"\\\\multicolumn{3}{c}{1-NN}\", table_str)\n",
    "table_str = re.sub(r\"[\\s]*adv-nn-k3-30 & [\\s]*advPruning-nn-k3-30\",\n",
    "                   r\"\\\\multicolumn{2}{c}{3-NN}\", table_str)\n",
    "table_str = re.sub(r\"[\\s]*adv-decision-tree-d5-30 & [\\s]*robust-decision-tree-d5-30 & [\\s]*advPruning-decision-tree-d5-30\",\n",
    "                   r\"\\\\multicolumn{3}{c}{DT}\", table_str)\n",
    "table_str = re.sub(r\"[\\s]*adv-rf-100-30-d5 & [\\s]*robust-rf-100-30-d5 & [\\s]*advPruning-rf-100-30-d5\",\n",
    "                   r\"\\\\multicolumn{3}{c||}{RF}\", table_str)\n",
    "table_str = re.sub(r\"[\\s]*adv-mlp-30 & [\\s]*advPruning-mlp-30\",\n",
    "                   r\" \\\\multicolumn{2}{c}{MLP}\", table_str)\n",
    "table_str = re.sub(r\"[\\s]*adv-logistic-regression-30 & [\\s]*advPruning-logistic-regression-30\",\n",
    "                   r\" \\\\multicolumn{2}{c}{LR}\", table_str)\n",
    "table_str = table_str.replace(\"RBA-Exact-KNN-k1-avg-pert & RBA-Exact-KNN-k1-avg-pert & RBA-Exact-KNN-k1-avg-pert\",\n",
    "                              \"AT & Wang's & AP\")\n",
    "table_str = table_str.replace(\"RBA-Approx-KNN-k3-50-avg-pert & RBA-Approx-KNN-k3-50-avg-pert\",\n",
    "                              \"AT & AP\")\n",
    "table_str = re.sub(r\"[\\s]*RBA-Exact-DT-avg-pert & [\\s]*RBA-Exact-DT-avg-pert & [\\s]*RBA-Exact-DT-avg-pert\",\n",
    "                    \" AT & RS & AP\", table_str)\n",
    "table_str = table_str.replace(\"RBA-Approx-RF-100-avg-pert & RBA-Approx-RF-100-avg-pert & RBA-Approx-RF-100-avg-pert\",\n",
    "                              \"AT & RS & AP\")\n",
    "table_str = re.sub(r\"[\\s]*pgd-avg-pert & [\\s]*pgd-avg-pert\",\n",
    "                    \" AT & AP\", table_str)\n",
    "table_str = table_str.replace(\"adv-nnopt-k1-all-avg-pert\", \"AT\")\n",
    "table_str = table_str.replace(\"advPruning-decision-tree-d5-30\", \"AP\")\n",
    "table_str = table_str.replace(\"llllllllllllllll\", \"l|ccc|cc|ccc|ccc||cc|cc\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/australian-random-forest-500-d10-blackbox-rs0-l2.json doesn't exist\n",
      "./results/covtypebin-10200-random-forest-500-d10-RBA-Approx-RF-100-rs0-l2.json doesn't exist\n"
     ]
    }
   ],
   "source": [
    "def attack_table(exp_name, grid_param):\n",
    "    table_str = gen_table(\n",
    "                    exp_name, grid_param, ['model', 'attack'], ['dataset'], combine_method=1,\n",
    "                    objs=['avg_pert'], additionals=[partial(bold_best, reverse=True)]\n",
    "                ).to_latex(escape=False)\n",
    "    table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "    table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "    table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "    table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", r\"$\\\\epsilon$\", table_str)\n",
    "    table_str = table_str.replace(\"llllllllllllll\", \"l|cccc|cccc|ccc|cc\")\n",
    "    table_str = table_str.replace(\"-avg-pert\", \"\")\n",
    "    table_str = table_str.replace(\"direct-k1\", \"Direct\")\n",
    "    table_str = table_str.replace(\"direct-k3\", \"Direct\")\n",
    "    table_str = table_str.replace(\"kernelsub-c1000-pgd\", \"Kernel\")\n",
    "    table_str = table_str.replace(\"RBA-Exact-KNN-k1\", \"RBA-Exact\")\n",
    "    table_str = table_str.replace(\"RBA-Exact-DT\", \"RBA-Exact\")\n",
    "    table_str = table_str.replace(\"RBA-Approx-KNN-k3-50\", \"RBA-Approx\")\n",
    "    table_str = table_str.replace(\"RBA-Approx-RF-100\", \"RBA-Approx\")\n",
    "    table_str = table_str.replace(\"dt-papernots\", \"Papernot's\")\n",
    "    table_str = table_str.replace(\"rev-nnopt-k3-50-region\", \"RBA-Approx\")\n",
    "    table_str = table_str.replace(\"rf-attack-rev-100\", \"RBA-Approx\")\n",
    "    table_str = table_str.replace(\"dt-attack-opt\", \"RBA-Exact\")\n",
    "    table_str = table_str.replace(\"decision-tree-d5\", \"DT\")\n",
    "    table_str = table_str.replace(\"random-forest-100-d5\", \"RF\")\n",
    "    table_str = table_str.replace(\"knn1\", \"1-NN\")\n",
    "    table_str = table_str.replace(\"knn3\", \"3-NN\")\n",
    "    table_str = table_str.replace(\"\\multicolumn{4}{l}\", \"\\multicolumn{4}{c}\")\n",
    "    table_str = table_str.replace(\"\\multicolumn{3}{l}\", \"\\multicolumn{3}{c}\")\n",
    "    table_str = table_str.replace(\"\\multicolumn{2}{l}\", \"\\multicolumn{2}{c}\")\n",
    "    table_str = table_str.replace(\"blackbox\", \"BBox\")\n",
    "    return table_str\n",
    "\n",
    "_, exp_name, grid_param, _ = compare_attacks()\n",
    "write_to_tex(attack_table(exp_name, grid_param), exp_name + '_table.tex')\n",
    "_, exp_name, grid_param, _ = params_l2.compare_attacks()()\n",
    "write_to_tex(attack_table(exp_name, grid_param), exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fns = [nn_k1_robustness_figs, nn_k3_robustness_figs, dt_robustness_figs, rf_robustness_figs]\n",
    "model_names = [\"1-NN\", \"3-NN\", \"Decision tree\", \"Random forest\"]\n",
    "def get_label_name(name):\n",
    "    if 'advPruning' in name:\n",
    "        return \"AP\"\n",
    "    elif 'robust' in name:\n",
    "        return \"RS\"\n",
    "    elif 'decision_tree' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'knn1' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'knn3' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'random_forest' in name:\n",
    "        return \"Reg.\"\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_label_color(name):\n",
    "    if 'advPruning' in name:\n",
    "        return \"#ff7f0e\"\n",
    "    elif 'robust' in name:\n",
    "        return \"#1f77b4\"\n",
    "    elif 'decision_tree' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'knn1' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'knn3' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'random_forest' in name:\n",
    "        return \"#7f7f7f\"\n",
    "        \n",
    "    return name\n",
    "\n",
    "def compare_nn_plots(exp_name, grid_param, caption='', show_plot=False):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param['ord'],\n",
    "    }\n",
    "    variables = ['model']\n",
    "    \n",
    "    fig_paths = plot_result(df, exp_name, control, variables,\n",
    "                            get_title_fn=lambda g: get_var_name(\"dataset\", g['dataset']),\n",
    "                            get_label_name_fn=get_label_name,\n",
    "                            get_label_color_fn=get_label_color,\n",
    "                            show_plot=show_plot)\n",
    "    return fig_paths\n",
    "\n",
    "def fig_paths_latex(fig_paths: List[List[Tuple[Dict, str]]], fig_label, caption):\n",
    "    ret = \"\"\"\n",
    "\\\\begin{figure}[ht!]\n",
    "\\\\centering\"\"\"\n",
    "    img_paths = []\n",
    "    for row in fig_paths:\n",
    "        for entry in row:\n",
    "            g, img_path = entry\n",
    "            ret += \"\"\"\n",
    "\\\\subfloat[%s]{\n",
    "    \\\\includegraphics[width=%.2f\\\\textwidth]{%s}}\"\"\" % (g['subfig_label'], 1/len(fig_paths[0]), img_path)\n",
    "        ret += \"\\n\"\n",
    "    ret += \"\"\"\n",
    "\\\\caption{%s}\n",
    "\\\\label{fig:%s}\n",
    "\\\\end{figure} \n",
    "\"\"\" % (caption, fig_label)\n",
    "    return ret\n",
    "\n",
    "fig_paths = []\n",
    "for i, fn in enumerate(exp_fns):\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    fig_path = compare_nn_plots(exp_name, grid_param, show_plot=False)\n",
    "    for g, _ in fig_path:\n",
    "        g['subfig_label'] = model_names[i]\n",
    "        g['subfig_label'] = get_var_name(\"dataset\", g['subfig_label'])\n",
    "    fig_paths.append(fig_path)\n",
    "transpose = [list() for c in fig_paths[0]]\n",
    "for i, col in enumerate(fig_paths):\n",
    "    for j, r in enumerate(col):\n",
    "        transpose[j].append(r)\n",
    "        \n",
    "caption = \"The maximum perturbation distance allowed versus accuracy.\"\n",
    "fig_str = fig_paths_latex(transpose[:5], \"defense-cmp\", caption)\n",
    "write_to_tex(fig_str, 'defense_cmp_fig.tex')\n",
    "\n",
    "fig_str = fig_paths_latex(transpose[5:], \"defense-cmp2\", caption)\n",
    "write_to_tex(fig_str, 'defense_cmp2_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, exp_name, grid_param, _ = compare_nns()\n",
    "#\n",
    "#def get_title_fn(g):\n",
    "#    ret = get_var_name(\"dataset\", g['dataset'])\n",
    "#    return ret\n",
    "#\n",
    "#def compare_nn_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "#    df = params_to_dataframe(grid_param)\n",
    "#    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "#\n",
    "#    control = {\n",
    "#        'dataset': datasets,\n",
    "#        'ord': grid_param[0]['ord'],\n",
    "#    }\n",
    "#    variables = ['model']\n",
    "#    figs = plot_result(df, exp_name, control, variables, get_title_fn=get_title_fn, show_plot=show_plot)\n",
    "#    fig_paths = []\n",
    "#    for i, f in enumerate(figs):\n",
    "#        if i % 3 == 0:\n",
    "#            fig_paths.append([])\n",
    "#        f[0]['subfig_label'] = f[0]['dataset']\n",
    "#        f[0]['subfig_label'] = get_var_name(\"dataset\", f[0]['subfig_label'])\n",
    "#        fig_paths[-1].append(f)\n",
    "#    \n",
    "#    return fig_paths_latex(fig_paths, exp_name, caption=caption)\n",
    "#caption = \"\"\"\n",
    "#The maximum perturbation distance allowed versus accuracy with different $k$ of $k$-NN classifier\n",
    "#using RBA-Approx attack searching 50 regions.\"\n",
    "#\"\"\"\n",
    "#fig_str = compare_nn_plots(exp_name, grid_param, caption=caption, show_plot=False)\n",
    "#write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import datasets, tree_datasets\n",
    "_, _, grid_param, _ = tst_scores()\n",
    "\n",
    "col_names = [\n",
    "    \"\\\\parbox{15mm}{\\\\centering \\# training \\\\\\\\ (1-NN, 3-NN)}\",\n",
    "    \"\\\\parbox{15mm}{\\\\centering \\# training \\\\\\\\ (DT, RF, MLP)}\",\n",
    "    \"\\\\parbox{15mm}{\\\\centering \\# testing \\\\\\\\ (perturbation)}\",\n",
    "    \"\\\\parbox{15mm}{\\\\centering \\# testing \\\\\\\\ (test accuracy)}\",\n",
    "    \"\\# features\",\n",
    "    \"\\# classes\",\n",
    "]\n",
    "ret = OrderedDict()\n",
    "for i, ds in enumerate(datasets):\n",
    "    X, y, _ = auto_var.get_var_with_argument(\"dataset\", ds)\n",
    "    tX, _, _ = auto_var.get_var_with_argument(\"dataset\", tree_datasets[i])\n",
    "    ret[auto_var.get_var_shown_name(\"dataset\", ds)] = OrderedDict([\n",
    "        (col_names[0], X.shape[0]-200),\n",
    "        (col_names[1], tX.shape[0]-200),\n",
    "        (col_names[2], 100),\n",
    "        (col_names[3], 200),\n",
    "        (col_names[4], X.shape[1]),\n",
    "        (col_names[5], 2),\n",
    "    ])\n",
    "df = pd.DataFrame(ret).T\n",
    "df = df[[c for c in col_names]]\n",
    "\n",
    "exp_name = \"dataset-stats\"\n",
    "caption = \"Dataset statistics.\"\n",
    "table_str = table_wrapper(df, table_name=exp_name, caption=caption)\n",
    "table_str = table_str.replace(\"lrrrrrr\", \"lcccccc\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_fonts(series):\n",
    "    if '\\\\# train' in series.name[1]:\n",
    "        return series.apply(lambda x: \"$%d$\" % x if not np.isnan(x) else \"-1\")\n",
    "    else:\n",
    "        return series.apply(lambda x: (\"$%.3f$\" % x) if x >= 1 else (\"$%.3f$\" % x).replace(\"0.\", \".\"))\n",
    "    \n",
    "def preprocess(grid_param):\n",
    "    models = [i.replace(\"_\", \"-\") for i in union_param_key(grid_param, 'model')]\n",
    "    attacks = []\n",
    "    for i in union_param_key(grid_param, 'attack'):\n",
    "        for s in ['-avg-pert', '-tst-score', '-aug-len', '-imp']:\n",
    "            attacks.append(i.replace(\"_\", \"-\") + s)\n",
    "    col_names = []\n",
    "    for model in models:\n",
    "        for attack in attacks:\n",
    "            if '-imp' in attack and model == models[0]:\n",
    "                continue\n",
    "            col_names.append((model, attack))\n",
    "    return col_names\n",
    "\n",
    "def process(task_fn):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    df = gen_table(exp_name, grid_param, ['model', 'attack'], ['dataset'],\n",
    "                   combine_method=1, objs=['tst_score', 'avg_pert', 'aug_len'],\n",
    "                   additionals=[])\n",
    "\n",
    "    models = [i.replace(\"_\", \"-\") for i in union_param_key(grid_param, 'model')]\n",
    "    attack = grid_param[0]['attack'][0].replace(\"_\", '-')\n",
    "    col_names = preprocess(grid_param)\n",
    "\n",
    "    df = df.apply(lambda a: a.apply(lambda b: float(str(b).replace(\"$\", \"\")) if b else b))\n",
    "    for model in models[1:]:\n",
    "        df[(model, attack + '-imp')] = df[(model, attack + '-avg-pert')] / df[(models[0], attack + '-avg-pert')]\n",
    "    df = df[col_names]\n",
    "    df = df.rename(index=str, columns={\n",
    "        attack + \"-aug-len\": \"\\# train\",\n",
    "        attack + \"-tst-score\": parbox(8, \"test \\\\\\\\ accuracy\"),\n",
    "        attack + \"-avg-pert\": parbox(9, \"ER\"),\n",
    "        attack + \"-imp\": \"\\\\defenderscore\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def postprocess(task_fn, df, rename_columns=None, caption=None):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    if rename_columns:\n",
    "        df = df.rename(index=str, columns=rename_columns)\n",
    "    df = df.apply(structure_fonts)\n",
    "    table_str = table_wrapper(df, table_name=exp_name, caption=caption)\n",
    "    #table_str = df.to_latex(escape=False)\n",
    "    table_str = table_str.replace(\"{l}\", \"{c}\")\n",
    "    table_str = table_str.replace(\"llllllllllllllll\", \"lccc|cccc|cccc|cccc\")\n",
    "    table_str = table_str.replace(\"$.000$\", \"-\")\n",
    "    table_str = table_str.replace(\"$nan$\", \"-\")\n",
    "    return table_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_template = \"\"\"\n",
    "The number of training data left after adversarial pruning (AP), testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen separation parameter of AP for {}.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Testing accuracy is a sanity check that we are not giving away all accuracy for robustness.\n",
    "The higher the empirical robustness is means the classifier is more robust to the given attack.\n",
    "When considering the strength of the attack, empirical robustness is lower the better.\n",
    "When considering the strength of the defense, \\\\defenderscore is higher the better.\n",
    "For \\\\defenderscore higher mean that after defense (AP), the classifier become more robust, thus higher the better.\n",
    "\"\"\"\n",
    "\n",
    "fn = nn_k1_robustness\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"1-NN\")\n",
    "rename_columns = {\n",
    "    \"knn1\": \"1-NN\",\n",
    "    \"advPruning-nn-k1-10\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-nn-k1-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-nn-k1-50\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = nn_k3_robustness\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"3-NN\")\n",
    "rename_columns = {\n",
    "    \"knn3\": \"3-NN\",\n",
    "    \"advPruning-nn-k3-10\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-nn-k3-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-nn-k3-50\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = dt_robustness\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"DT\")\n",
    "rename_columns = {\n",
    "    \"decision-tree-d5\": \"DT\",\n",
    "    \"advPruning-decision-tree-d5-10\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-decision-tree-d5-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-decision-tree-d5-50\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = rf_robustness\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"RF\")\n",
    "rename_columns = {\n",
    "    \"random-forest-100-d5\": \"RF\",\n",
    "    \"advPruning-rf-100-10-d5\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-rf-100-30-d5\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-rf-100-50-d5\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = lr_ap_robustness\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"LR\")\n",
    "rename_columns = {\n",
    "    \"logistic-regression\": \"LR\",\n",
    "    \"advPruning-logistic-regression-10\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-logistic-regression-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-logistic-regression-50\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = mlp_ap_robustness\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"MLP\")\n",
    "rename_columns = {\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"advPruning-mlp-10\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-mlp-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-mlp-50\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-52ae77481bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_l2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k1_robustness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mcaption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaption_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1-NN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m rename_columns = {\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process' is not defined"
     ]
    }
   ],
   "source": [
    "caption_template = \"\"\"\n",
    "The number of training data left after adversarial pruning (AP), testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen separation parameter of AP for {}.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Testing accuracy is a sanity check that we are not giving away all accuracy for robustness.\n",
    "The higher the empirical robustness is means the classifier is more robust to the given attack.\n",
    "When considering the strength of the attack, empirical robustness is lower the better.\n",
    "When considering the strength of the defense, \\\\defenderscore is higher the better.\n",
    "For \\\\defenderscore higher mean that after defense (AP), the classifier become more robust, thus higher the better.\n",
    "\"\"\"\n",
    "\n",
    "fn = params_l2.nn_k1_robustness()\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"1-NN\")\n",
    "rename_columns = {\n",
    "    \"knn1\": \"1-NN\",\n",
    "    \"advPruning-nn-k1-25\": \"AP (separation parameter $r$=.25)\",\n",
    "    \"advPruning-nn-k1-50\": \"AP (separation parameter $r$=.50)\",\n",
    "    \"advPruning-nn-k1-75\": \"AP (separation parameter $r$=.75)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = params_l2.nn_k3_robustness()\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"3-NN\")\n",
    "rename_columns = {\n",
    "    \"knn3\": \"3-NN\",\n",
    "    \"advPruning-nn-k3-25\": \"AP (separation parameter $r$=.25)\",\n",
    "    \"advPruning-nn-k3-50\": \"AP (separation parameter $r$=.50)\",\n",
    "    \"advPruning-nn-k3-75\": \"AP (separation parameter $r$=.75)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = params_l2.dt_robustness()\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"DT\")\n",
    "rename_columns = {\n",
    "    \"decision-tree-d5\": \"DT\",\n",
    "    \"advPruning-decision-tree-d5-25\": \"AP (separation parameter $r$=.25)\",\n",
    "    \"advPruning-decision-tree-d5-50\": \"AP (separation parameter $r$=.50)\",\n",
    "    \"advPruning-decision-tree-d5-75\": \"AP (separation parameter $r$=.75)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = params_l2.rf_robustness()\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"RF\")\n",
    "rename_columns = {\n",
    "    \"random-forest-100-d5\": \"RF\",\n",
    "    \"advPruning-rf-100-25-d5\": \"AP (separation parameter $r$=.25)\",\n",
    "    \"advPruning-rf-100-50-d5\": \"AP (separation parameter $r$=.50)\",\n",
    "    \"advPruning-rf-100-75-d5\": \"AP (separation parameter $r$=.75)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = params_l2.lr_ap_robustness()\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"LR\")\n",
    "rename_columns = {\n",
    "    \"logistic-regression\": \"LR\",\n",
    "    \"advPruning-logistic-regression-25\": \"AP (separation parameter $r$=.25)\",\n",
    "    \"advPruning-logistic-regression-50\": \"AP (separation parameter $r$=.50)\",\n",
    "    \"advPruning-logistic-regression-75\": \"AP (separation parameter $r$=.75)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = params_l2.mlp_ap_robustness()\n",
    "df = process(fn)\n",
    "caption = caption_template.format(\"MLP\")\n",
    "rename_columns = {\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"advPruning-mlp-25\": \"AP (separation parameter $r$=.25)\",\n",
    "    \"advPruning-mlp-50\": \"AP (separation parameter $r$=.50)\",\n",
    "    \"advPruning-mlp-75\": \"AP (separation parameter $r$=.75)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process2(task_fn):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    df = gen_table(exp_name, grid_param, ['model', 'attack'], ['dataset'],\n",
    "                   combine_method=1, objs=['tst_score', 'avg_pert'], additionals=[])\n",
    "\n",
    "    models = [i.replace(\"_\", \"-\") for i in union_param_key(grid_param, 'model')]\n",
    "    attack = grid_param[0]['attack'][0].replace(\"_\", '-')\n",
    "    col_names = [a for a in preprocess(grid_param) if '-aug-len' not in a[1]]\n",
    "\n",
    "    df = df.apply(lambda a: a.apply(lambda b: float(str(b).replace(\"$\", \"\")) if b else b))\n",
    "    for model in models[1:]:\n",
    "        df[(model, attack + '-imp')] = df[(model, attack + '-avg-pert')] / df[(models[0], attack + '-avg-pert')]\n",
    "    df = df[col_names]\n",
    "    df = df.rename(index=str, columns={\n",
    "        attack + \"-tst-score\": parbox(8, \"testing \\\\\\\\ accuracy\"),\n",
    "        attack + \"-avg-pert\": parbox(9, \"empirical \\\\\\\\ robustness\"),\n",
    "        attack + \"-imp\": \"\\\\defenderscore\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def postprocess2(task_fn, df, rename_columns, caption):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    df = df.rename(index=str, columns=rename_columns)\n",
    "    df = df.apply(structure_fonts)\n",
    "    table_str = table_wrapper(df, table_name=exp_name, caption=caption,)\n",
    "    #table_str = df.to_latex(escape=False)\n",
    "    table_str = table_str.replace(\"{l}\", \"{c}\")\n",
    "    table_str = table_str.replace(\"llllllllllll\", \"lcc|ccc|ccc|ccc\")\n",
    "    table_str = table_str.replace(\"$.000$\", \"-\")\n",
    "    table_str = table_str.replace(\"$nan$\", \"-\")\n",
    "    return table_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_template = \"\"\"\n",
    "The testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen attack distance of adversarial training (AT) for {}.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Testing accuracy is a sanity check that we are not giving away all accuracy for robustness.\n",
    "The higher the empirical robustness is means the classifier is more robust to the given attack.\n",
    "For \\\\defenderscore higher mean that after defense (AP), the classifier become more robust, thus higher the better.\n",
    "\"\"\"\n",
    "\n",
    "fn = mlp_at_robustness\n",
    "df = process2(fn)\n",
    "caption = caption_template.format(\"MLP\")\n",
    "rename_columns = {\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"adv-mlp-10\": \"AT (attack distance $r$=.1)\",\n",
    "    \"adv-mlp-30\": \"AT (attack distance $r$=.3)\",\n",
    "    \"adv-mlp-50\": \"AT (attack distance $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess2(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = lr_at_robustness\n",
    "df = process2(fn)\n",
    "caption = caption_template.format(\"LR\")\n",
    "rename_columns = {\n",
    "    \"logistic-regression\": \"LR\",\n",
    "    \"adv-logistic-regression-10\": \"AT (attack distance $r$=.1)\",\n",
    "    \"adv-logistic-regression-30\": \"AT (attack distance $r$=.3)\",\n",
    "    \"adv-logistic-regression-50\": \"AT (attack distance $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess2(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "\n",
    "fn = params_l2.mlp_at_robustness()\n",
    "df = process2(fn)\n",
    "caption = caption_template.format(\"MLP\")\n",
    "rename_columns = {\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"adv-mlp-25\": \"AT (attack distance $r$=.25)\",\n",
    "    \"adv-mlp-50\": \"AT (attack distance $r$=.50)\",\n",
    "    \"adv-mlp-75\": \"AT (attack distance $r$=.75)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess2(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = params_l2.lr_at_robustness()\n",
    "df = process2(fn)\n",
    "caption = caption_template.format(\"LR\")\n",
    "rename_columns = {\n",
    "    \"logistic-regression\": \"LR\",\n",
    "    \"adv-logistic-regression-25\": \"AT (attack distance $r$=.25)\",\n",
    "    \"adv-logistic-regression-50\": \"AT (attack distance $r$=.50)\",\n",
    "    \"adv-logistic-regression-75\": \"AT (attack distance $r$=.75)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess2(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/fashion-mnist35-2200-pca25-adv-nn-k1-75-RBA-Exact-KNN-k1-rs0-l2.json doesn't exist\n",
      "./results/fashion-mnist06-2200-pca25-adv-nn-k1-75-RBA-Exact-KNN-k1-rs0-l2.json doesn't exist\n",
      "./results/mnist17-2200-pca25-adv-nn-k1-75-RBA-Exact-KNN-k1-rs0-l2.json doesn't exist\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a8f0b285ec52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mds_eps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_l2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_l2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn1_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mds_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'AT'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Wang's\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AP'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'knn1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a8f0b285ec52>\u001b[0m in \u001b[0;36mdef_process\u001b[0;34m(task_fn)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munion_param_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mattack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attack'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcol_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "def def_process(task_fn):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    df = gen_table(exp_name, grid_param, ['model', 'attack'], ['dataset'],\n",
    "                   combine_method=0, objs=['tst_score', 'avg_pert', 'aug_len'],\n",
    "                   additionals=[])\n",
    "\n",
    "    models = [i.replace(\"_\", \"-\") for i in union_param_key(grid_param, 'model')]\n",
    "    attack = grid_param[0]['attack'][0].replace(\"_\", '-')\n",
    "    col_names = preprocess(grid_param)\n",
    "\n",
    "    df = df.apply(lambda a: a.apply(lambda b: float(str(b).replace(\"$\", \"\")) if b else b))\n",
    "    for model in models[1:]:\n",
    "        df[(model, attack + '-imp')] = df[(model, attack + '-avg-pert')] / df[(models[0], attack + '-avg-pert')]\n",
    "    df = df[col_names]\n",
    "    df = df.rename(index=str, columns={\n",
    "        attack + \"-aug-len\": \"\\# train\",\n",
    "        attack + \"-tst-score\": parbox(8, \"test \\\\\\\\ accuracy\"),\n",
    "        attack + \"-avg-pert\": parbox(9, \"ER\"),\n",
    "        attack + \"-imp\": \"\\\\defenderscore\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "ds = ['australian', 'cancer', 'covtype', 'diabetes', 'f-mnist06', 'f-mnist35', 'fourclass', 'halfmoon', 'mnist17']\n",
    "table = OrderedDict()\n",
    "ds_eps = params_l2.ds_eps\n",
    "\n",
    "df = def_process(params_l2.nn1_def())\n",
    "ds_def = {'AT': np.zeros(len(ds)), \"Wang's\": np.zeros(len(ds)), 'AP': np.zeros(len(ds))}\n",
    "for idx in df['knn1'].index:\n",
    "    ds_name = idx[0]\n",
    "    ds_idx = ds.index(idx[0])\n",
    "    ds_def['AT'][ds_idx] = df[f'adv-nn-k1-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "    ds_def[\"Wang's\"][ds_idx] = df[f'robustv2-nn-k1-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "    ds_def['AP'][ds_idx] = df[f'advPruning-nn-k1-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "table['1-NN'] = ds_def\n",
    "\n",
    "df = def_process(params_l2.nn3_def())\n",
    "ds_def = {'AT': np.zeros(len(ds)), 'AP': np.zeros(len(ds))}\n",
    "for idx in df['knn3'].index:\n",
    "    ds_name = idx[0]\n",
    "    ds_idx = ds.index(idx[0])\n",
    "    ds_def['AT'][ds_idx] = df[f'adv-nn-k3-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "    ds_def['AP'][ds_idx] = df[f'advPruning-nn-k3-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "table['3-NN'] = ds_def\n",
    "\n",
    "df = def_process(params_l2.rf_def())\n",
    "ds_def = OrderedDict([('AT', np.zeros(len(ds))), ('RS', np.zeros(len(ds))), ('AP', np.zeros(len(ds)))])\n",
    "for idx in df['random-forest-100-d5'].index:\n",
    "    ds_name = idx[0]\n",
    "    ds_idx = ds.index(idx[0])\n",
    "    ds_def['AT'][ds_idx] = df[f'adv-rf-100-{ds_eps[ds_name]}-d5']['\\defenderscore'][ds_name][0]\n",
    "    ds_def['RS'][ds_idx] = df[f'robust-rf-100-{ds_eps[ds_name]}-d5']['\\defenderscore'][ds_name][0]\n",
    "    ds_def['AP'][ds_idx] = df[f'advPruning-rf-100-{ds_eps[ds_name]}-d5']['\\defenderscore'][ds_name][0]\n",
    "table['RF'] = ds_def\n",
    "\n",
    "df = def_process(params_l2.dt_def())\n",
    "ds_def = OrderedDict([('AT', np.zeros(len(ds))), ('RS', np.zeros(len(ds))), ('AP', np.zeros(len(ds)))])\n",
    "for idx in df['decision-tree-d5'].index:\n",
    "    ds_name = idx[0]\n",
    "    ds_idx = ds.index(idx[0])\n",
    "    ds_def['AT'][ds_idx] = df[f'adv-decision-tree-d5-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "    ds_def['RS'][ds_idx] = df[f'robust-decision-tree-d5-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "    ds_def['AP'][ds_idx] = df[f'advPruning-decision-tree-d5-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "table['DT'] = ds_def\n",
    "\n",
    "df = def_process(params_l2.lr_def())\n",
    "ds_def = OrderedDict([('AT', np.zeros(len(ds))), ('AP', np.zeros(len(ds)))])\n",
    "for idx in df['logistic-regression'].index:\n",
    "    ds_name = idx[0]\n",
    "    ds_idx = ds.index(idx[0])\n",
    "    ds_def['AT'][ds_idx] = df[f'adv-logistic-regression-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "    ds_def['AP'][ds_idx] = df[f'advPruning-logistic-regression-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "table['LR'] = ds_def\n",
    "\n",
    "df = def_process(params_l2.mlp_def())\n",
    "ds_def = OrderedDict([('AT', np.zeros(len(ds))), ('AP', np.zeros(len(ds)))])\n",
    "for idx in df['mlp'].index:\n",
    "    ds_name = idx[0]\n",
    "    ds_idx = ds.index(idx[0])\n",
    "    ds_def['AT'][ds_idx] = df[f'adv-mlp-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "    ds_def['AP'][ds_idx] = df[f'advPruning-mlp-{ds_eps[ds_name]}']['\\defenderscore'][ds_name][0]\n",
    "table['MLP'] = ds_def\n",
    "\n",
    "df = pd.DataFrame(flatten(table), index=ds)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(s):\n",
    "    max_value = s.max()\n",
    "    ret = s.apply(lambda x: '$%.2f$' % x if x != max_value else '$\\\\mathbf{%.2f}$' % x)\n",
    "    return ret\n",
    "df = df.fillna(-1)\n",
    "for model_name in ['1-NN', '3-NN', 'DT', 'LR', 'MLP', 'RF']:\n",
    "    df[model_name] = df[model_name].apply(to_str, axis=1)\n",
    "table_str = df.to_latex(escape=False)\n",
    "table_str = table_str.replace(\"{l}\", \"{c}\")\n",
    "table_str = table_str.replace(\"llllllllllllllll\", \"lccc|cc|ccc|ccc|cc|cc\")\n",
    "table_str = table_str.replace(\"$.000$\", \"-\")\n",
    "table_str = table_str.replace(\"$nan$\", \"-\")\n",
    "\n",
    "write_to_tex(table_str, 'compare_defense_table_l2.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/fullmnist-pca100-xgb-xgb-models-prune-fullmnist-pca100-20-rf-linf.0200.modelknn1-blackbox-rs0-linf.json doesn't exist\n",
      "./results/fullfashion-pca100-xgb-xgb-models-prune-fullfashion-pca100-20-rf-linf.0200.model-blackbox-rs0-linf.json doesn't exist\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2dbcaedce0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmodel_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "_, exp_name, grid_params, _ = params.fullds()()\n",
    "df = params_to_dataframe(grid_params, columns=[(\"tst_score\"), (\"avg_pert\"), \"aug_len\"])\n",
    "table = {}\n",
    "mnist_model_names = ['random_forest_500_d10', 'approxAP_rf_500_20_d10',\n",
    "                     'knn1', 'approxAP_nn_k1_20',\n",
    "                     'knn3', 'approxAP_nn_k3_20',\n",
    "                     'xgb_xgb_models/prune_fullmnist_pca100_20_linf.unrob.0200.model',\n",
    "                     'xgb_xgb_models/prune_fullmnist_pca100_20_linf.0200.model',\n",
    "                    ]\n",
    "fashion_model_names = ['random_forest_500_d10', 'approxAP_rf_500_20_d10',\n",
    "                       'knn1', 'approxAP_nn_k1_20',\n",
    "                       'knn3', 'approxAP_nn_k3_20',\n",
    "                       'xgb_xgb_models/prune_fashion_pca100_20_linf.unrob.0200.model',\n",
    "                       'xgb_xgb_models/prune_fashion_pca100_20_linf.0200.model',\n",
    "                      ]\n",
    "shown_names = ['RF', 'AP RF', '$1$-NN', 'AP $1$-NN', '$3$-NN', 'AP $3$-NN']\n",
    "for ds_name_t, d in df.groupby(\"dataset\"):\n",
    "    ds_name = ds_name_t.split(\"_\")[0]\n",
    "    if 'mnist' in ds_name:\n",
    "        model_names = mnist_model_names\n",
    "    else:\n",
    "        model_names = fashion_model_names\n",
    " \n",
    "    table[ds_name] = []\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        model_df = d[d['model'] == model_name]\n",
    "        table[ds_name].append(\"%.3f\" % model_df['tst_score'].values[0])\n",
    "        table[ds_name].append(\"%.3f\" % model_df['avg_pert'].values[0])\n",
    "        if i % 2:\n",
    "            table[ds_name].append(\n",
    "                \"%.3f\" % (model_df['avg_pert'].values[0] / d[d['model'] == model_names[i-1]]['avg_pert'].values[0]))\n",
    "table = pd.DataFrame.from_dict(table, orient='index', columns=[\n",
    "    ('RF', 'natural', 'acc.'), ('RF', 'natural', 'ER'),\n",
    "    ('RF', 'AP', 'acc.'), ('RF', 'AP', 'ER'), ('RF', 'AP', '\\\\defscore'),\n",
    "    ('$1$-NN', 'natural', 'acc.'), ('$1$-NN', 'natural', 'ER'),\n",
    "    ('$1$-NN', 'AP', 'acc.'), ('$1$-NN', 'AP', 'ER'), ('$1$-NN', 'AP', '\\\\defscore'),\n",
    "    ('$3$-NN', 'natural', 'acc.'), ('$3$-NN', 'natural', 'ER'),\n",
    "    ('$3$-NN', 'AP', 'acc.'), ('$3$-NN', 'AP', 'ER'), ('$3$-NN', 'AP', '\\\\defscore'),\n",
    "])\n",
    "table.columns = pd.MultiIndex.from_tuples(table.columns, names=['model', 'method', ''])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/fullfashion-knn3-blackbox-rs0-l2.json doesn't exist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"5\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"5\" halign=\"left\">$1$-NN</th>\n",
       "      <th colspan=\"5\" halign=\"left\">$3$-NN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th colspan=\"3\" halign=\"left\">natural</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">natural</th>\n",
       "      <th colspan=\"3\" halign=\"left\">AP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">natural</th>\n",
       "      <th colspan=\"3\" halign=\"left\">AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>acc.</th>\n",
       "      <th>ER</th>\n",
       "      <th>acc.</th>\n",
       "      <th>ER</th>\n",
       "      <th>\\defscore</th>\n",
       "      <th>acc.</th>\n",
       "      <th>ER</th>\n",
       "      <th>acc.</th>\n",
       "      <th>ER</th>\n",
       "      <th>\\defscore</th>\n",
       "      <th>acc.</th>\n",
       "      <th>ER</th>\n",
       "      <th>acc.</th>\n",
       "      <th>ER</th>\n",
       "      <th>\\defscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fullfashion</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.907</td>\n",
       "      <td>1.336</td>\n",
       "      <td>0.880</td>\n",
       "      <td>2.273</td>\n",
       "      <td>0.855</td>\n",
       "      <td>2.752</td>\n",
       "      <td>1.211</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>2.885</td>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullmnist</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.823</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.965</td>\n",
       "      <td>2.597</td>\n",
       "      <td>0.970</td>\n",
       "      <td>2.612</td>\n",
       "      <td>1.006</td>\n",
       "      <td>0.970</td>\n",
       "      <td>3.066</td>\n",
       "      <td>0.975</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model            RF                                 $1$-NN                \\\n",
       "method      natural                   AP           natural            AP   \n",
       "               acc.     ER   acc.     ER \\defscore    acc.     ER   acc.   \n",
       "fullfashion   0.860  0.679  0.840  0.907     1.336   0.880  2.273  0.855   \n",
       "fullmnist     0.970  0.755  0.975  0.823     1.090   0.965  2.597  0.970   \n",
       "\n",
       "model                         $3$-NN                                  \n",
       "method                       natural             AP                   \n",
       "                ER \\defscore    acc.      ER   acc.     ER \\defscore  \n",
       "fullfashion  2.752     1.211  -1.000  -1.000  0.830  2.885    -1.000  \n",
       "fullmnist    2.612     1.006   0.970   3.066  0.975  3.050     0.995  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, exp_name, grid_params, _ = params_l2.fullds()()\n",
    "df = params_to_dataframe(grid_params, columns=[(\"tst_score\"), (\"avg_pert\"), \"aug_len\"])\n",
    "table = {}\n",
    "model_names = ['random_forest_300_d10', 'approxAP_rf_300_500_d10',\n",
    "               'knn1', 'approxAP_nn_k1_500',\n",
    "               'knn3', 'approxAP_nn_k3_500']\n",
    "shown_names = ['RF', 'AP RF', '$1$-NN', 'AP $1$-NN', '$3$-NN', 'AP $3$-NN']\n",
    "for ds_name_t, d in df.groupby(\"dataset\"):\n",
    "    ds_name = ds_name_t.split(\"_\")[0]\n",
    " \n",
    "    table[ds_name] = []\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        model_df = d[d['model'] == model_name]\n",
    "        if len(model_df['tst_score'].values) == 0:\n",
    "            table[ds_name].append(\"%.3f\" % -1)\n",
    "            table[ds_name].append(\"%.3f\" % -1)\n",
    "            if i % 2:\n",
    "                table[ds_name].append(\"%.3f\" % -1)\n",
    "        else:\n",
    "            table[ds_name].append(\"%.3f\" % model_df['tst_score'].values[0])\n",
    "            table[ds_name].append(\"%.3f\" % model_df['avg_pert'].values[0])\n",
    "            if i % 2:\n",
    "                try:\n",
    "                    table[ds_name].append(\n",
    "                        \"%.3f\" % (model_df['avg_pert'].values[0] / d[d['model'] == model_names[i-1]]['avg_pert'].values[0]))\n",
    "                except:\n",
    "                    table[ds_name].append(\"%.3f\" % -1)\n",
    "\n",
    "\n",
    "table = pd.DataFrame.from_dict(table, orient='index', columns=[\n",
    "    ('RF', 'natural', 'acc.'), ('RF', 'natural', 'ER'),\n",
    "    ('RF', 'AP', 'acc.'), ('RF', 'AP', 'ER'), ('RF', 'AP', '\\\\defscore'),\n",
    "    ('$1$-NN', 'natural', 'acc.'), ('$1$-NN', 'natural', 'ER'),\n",
    "    ('$1$-NN', 'AP', 'acc.'), ('$1$-NN', 'AP', 'ER'), ('$1$-NN', 'AP', '\\\\defscore'),\n",
    "    ('$3$-NN', 'natural', 'acc.'), ('$3$-NN', 'natural', 'ER'),\n",
    "    ('$3$-NN', 'AP', 'acc.'), ('$3$-NN', 'AP', 'ER'), ('$3$-NN', 'AP', '\\\\defscore'),\n",
    "])\n",
    "table.columns = pd.MultiIndex.from_tuples(table.columns, names=['model', 'method', ''])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bash ./sync_report.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-788ee363e0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0013778387416945 0.975\n",
      "2.8270121861572393 0.975\n",
      "1.0616784226959668\n"
     ]
    }
   ],
   "source": [
    "a = json.load(open(\"./results/fullmnist-approxAP-faisslshknn-1-500-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(a['avg_pert']['avg'], a['tst_score'])\n",
    "b = json.load(open(\"./results/fullmnist-faisslshknn-1-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], a['tst_score'])\n",
    "print(\"defscore:\", a['avg_pert']['avg'] / b['avg_pert']['avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.282651720246348 0.85\n",
      "1.7274246510334774 0.85\n",
      "1.3214189799136484\n"
     ]
    }
   ],
   "source": [
    "a = json.load(open(\"./results/fullfashion-approxAP-faisslshknn-1-500-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(a['avg_pert']['avg'], a['tst_score'])\n",
    "b = json.load(open(\"./results/fullfashion-faisslshknn-1-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], a['tst_score'])\n",
    "print(\"defscore:\", a['avg_pert']['avg'] / b['avg_pert']['avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5109409658739648 0.995\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/fullmnist-adv-mlp-500-blackbox-rs0-l2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-4ef6bfc0d60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullmnist-mlp-blackbox-rs0-l2.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullmnist-adv-mlp-500-blackbox-rs0-l2.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/fullmnist-adv-mlp-500-blackbox-rs0-l2.json'"
     ]
    }
   ],
   "source": [
    "a = json.load(open(\"./results/fullmnist-mlp-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(a['avg_pert']['avg'], a['tst_score'])\n",
    "b = json.load(open(\"./results/fullmnist-adv-mlp-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], a['tst_score'])\n",
    "print(\"defscore:\", a['avg_pert']['avg'] / b['avg_pert']['avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5274696356576869 0.885\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/fullfashion-adv-mlp-500-blackbox-rs0-l2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7314e2406471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullfashion-mlp-blackbox-rs0-l2.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullfashion-adv-mlp-500-blackbox-rs0-l2.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/fullfashion-adv-mlp-500-blackbox-rs0-l2.json'"
     ]
    }
   ],
   "source": [
    "a = json.load(open(\"./results/fullfashion-mlp-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(a['avg_pert']['avg'], a['tst_score'])\n",
    "b = json.load(open(\"./results/fullfashion-adv-mlp-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], a['tst_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.923543828315131 2.92527918559083 0.9994067720837564\n"
     ]
    }
   ],
   "source": [
    "a = json.load(open(\"./results/fullmnist-approxAP-faisslshknn-3-500-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "b = json.load(open(\"./results/fullmnist-faisslshknn-3-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(a['avg_pert']['avg'], b['avg_pert']['avg'], a['avg_pert']['avg'] / b['avg_pert']['avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/fourclass-adv-nn-k3-50-RBA-Approx-KNN-k3-50-rs0-l2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-919498367f57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fourclass-adv-nn-k3-50-RBA-Approx-KNN-k3-50-rs0-l2.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/fourclass-adv-nn-k3-50-RBA-Approx-KNN-k3-50-rs0-l2.json'"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fourclass-adv-nn-k3-50-RBA-Approx-KNN-k3-50-rs0-l2.json\", \"r\"))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2165064434846863\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/fullfashion-pca100-approxAP-nn-k3-30-blackbox-rs0-linf.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-981585984763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullfashion-pca100-knn3-blackbox-rs0-linf.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullfashion-pca100-approxAP-nn-k3-30-blackbox-rs0-linf.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aug_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/fullfashion-pca100-approxAP-nn-k3-30-blackbox-rs0-linf.json'"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullfashion-pca100-knn3-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'])\n",
    "b = json.load(open(\"./results/fullfashion-pca100-approxAP-nn-k3-30-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2331120206322521\n",
      "0.2693203900009394 55452\n"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullmnist-pca100-knn3-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'])\n",
    "b = json.load(open(\"./results/fullmnist-pca100-approxAP-nn-k3-20-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0660240009112116 0.97\n",
      "3.049811364060364 54684 0.975\n"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullmnist-knn3-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['tst_score'])\n",
    "b = json.load(open(\"./results/fullmnist-approxAP-nn-k3-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'], b['tst_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2734032264149424 0.88\n",
      "2.7521241654983055 33436 0.855\n"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullfashion-knn1-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['tst_score'])\n",
    "b = json.load(open(\"./results/fullfashion-approxAP-nn-k1-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'], b['tst_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/fullfashion-knn3-blackbox-rs0-l2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3fdef644a7b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullfashion-knn3-blackbox-rs0-l2.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullfashion-approxAP-nn-k3-500-blackbox-rs0-l2.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aug_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/fullfashion-knn3-blackbox-rs0-l2.json'"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullfashion-knn3-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['tst_score'])\n",
    "b = json.load(open(\"./results/fullfashion-approxAP-nn-k3-500-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'], b['tst_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7551389015055611 0.97\n",
      "0.8230184196777338 54684 0.975\n"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullmnist-random-forest-300-d10-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['tst_score'])\n",
    "b = json.load(open(\"./results/fullmnist-approxAP-rf-300-500-d10-blackbox-rs0-l2.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'], b['tst_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14094776912708767 0.95\n",
      "0.1521828053332865 55452 0.935\n"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullmnist-pca100-random-forest-500-d10-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['tst_score'])\n",
    "b = json.load(open(\"./results/fullmnist-pca100-approxAP-rf-500-20-d10-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'], b['tst_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17671626457944511 0.82\n",
      "0.19389134351629764 31458 0.8\n"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullfashion-pca100-random-forest-300-d10-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['tst_score'])\n",
    "b = json.load(open(\"./results/fullfashion-pca100-approxAP-rf-300-20-d10-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'], b['tst_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1509836874064058 0.95\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/fullmnist-pca10030-d10-blackbox-rs0-linf.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4f5783e6d25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullmnist-pca100-random-forest-300-d10-blackbox-rs0-linf.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/fullmnist-pca10030-d10-blackbox-rs0-linf.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aug_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tst_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/fullmnist-pca10030-d10-blackbox-rs0-linf.json'"
     ]
    }
   ],
   "source": [
    "b = json.load(open(\"./results/fullmnist-pca100-random-forest-300-d10-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['tst_score'])\n",
    "b = json.load(open(\"./results/fullmnist-pca10030-d10-blackbox-rs0-linf.json\", \"r\"))\n",
    "print(b['avg_pert']['avg'], b['aug_len'], b['tst_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
